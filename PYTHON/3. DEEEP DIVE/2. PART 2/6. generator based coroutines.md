- [COROUTINES](#coroutines)
- [GENERATOR STATES](#states)
- [SENDING DATA TO GENERATORS](#sending-data)
- [SENDING EXCEPTIONS TO GENERATORS](#exceptions)
- [USING DECORATORS TO PRIME COROUTINES](#decorators)
- [YIELD FROM - TWO WAY COMMUNICATION](#two-way)
- [YIELD FROM - SENDING DATA](#yield-sending-data)
- [YIELD FROM - CLOSING AND RETURN](#closing)
- [YIELD FROM - THROWING EXCEPTIONS](#throwing-exceptions)
- [PIPELINES - PULLING DATA](#pulling-data)
- [PIPELINES - BROADCASTING](#broadcasting)
  
<a id='coroutines'></a>
# Coroutines in Python

Coroutines are a special type of function in Python designed for cooperative multitasking. Unlike regular functions, coroutines can pause execution and yield control back to the caller, allowing other code to run. They are primarily used for asynchronous programming, data pipelines, and event-driven programming.

---

## 1. **What are Coroutines?**
- A coroutine is a generator-like function that can be paused and resumed during execution.
- Instead of producing a series of values (like generators), coroutines consume values or perform tasks in response to inputs.

---

## 2. **Defining and Using Coroutines**

### 2.1 Defining a Coroutine
- Coroutines are defined using the `async def` keyword in modern Python.
- You can also use regular generator functions with `yield` and `send()` for coroutine-like behavior.

### 2.2 Example: Basic Coroutine
```python
# Coroutine to consume values
async def simple_coroutine():
    print("Coroutine started")
    await asyncio.sleep(1)  # Simulates asynchronous behavior
    print("Coroutine ended")
```

---

## 3. **Creating Coroutines with `yield` and `send()`**

Coroutines in Python can be created using generator functions. The `send()` method allows values to be sent into the generator, making it act like a coroutine.

### Example:
```python
def echo_coroutine():
    print("Coroutine started")
    while True:
        received = yield  # Pauses execution and waits for input
        print(f"Received: {received}")

# Usage
echo = echo_coroutine()
next(echo)  # Prime the coroutine

echo.send("Hello")  # Output: Received: Hello
echo.send("World")  # Output: Received: World
echo.close()  # Stops the coroutine
```

---

## 4. **Modern Coroutines with `async` and `await`**

Python introduced `async def` and `await` in Python 3.5 to create and manage coroutines more intuitively.

### 4.1 Example: Basic `async` and `await`
```python
import asyncio

async def greet():
    print("Hello")
    await asyncio.sleep(1)  # Simulate an asynchronous task
    print("World")

# Running the coroutine
asyncio.run(greet())
```

---

## 5. **Using Coroutines for Data Pipelines**

Coroutines can be used to build data pipelines that process streams of data incrementally.

### Example:
```python
def data_pipeline():
    try:
        while True:
            data = yield
            print(f"Processing {data}")
    except GeneratorExit:
        print("Pipeline closed")

# Usage
pipeline = data_pipeline()
next(pipeline)  # Prime the coroutine
pipeline.send("Data1")  # Output: Processing Data1
pipeline.send("Data2")  # Output: Processing Data2
pipeline.close()  # Output: Pipeline closed
```

---

## 6. **Asynchronous I/O with Coroutines**

Coroutines are extensively used in asynchronous I/O operations, such as handling multiple network connections.

### Example:
```python
import asyncio

async def fetch_data(url):
    print(f"Fetching data from {url}")
    await asyncio.sleep(2)  # Simulate network delay
    print(f"Data fetched from {url}")

async def main():
    await asyncio.gather(
        fetch_data("https://example.com/1"),
        fetch_data("https://example.com/2"),
        fetch_data("https://example.com/3")
    )

asyncio.run(main())
```
**Output:**
```
Fetching data from https://example.com/1
Fetching data from https://example.com/2
Fetching data from https://example.com/3
Data fetched from https://example.com/1
Data fetched from https://example.com/2
Data fetched from https://example.com/3
```

---

## 7. **Difference Between Coroutines and Generators**

| **Feature**               | **Coroutines**                          | **Generators**                         |
|---------------------------|-----------------------------------------|-----------------------------------------|
| **Primary Purpose**       | Consuming data or performing tasks      | Producing data                          |
| **Pause/Resume**          | Use `await` for pausing and resuming    | Use `yield` for producing values        |
| **Communication**         | Can send and receive data               | Primarily produce data                  |
| **Syntax**                | `async def` and `await`                 | `def` and `yield`                       |

---

## 8. **Common Use Cases for Coroutines**

1. **Asynchronous I/O:**
   - Managing network requests, file operations, or database queries concurrently.

2. **Data Pipelines:**
   - Processing streaming data in real-time.

3. **Task Scheduling:**
   - Running multiple tasks concurrently with controlled execution.

4. **Event-Driven Programming:**
   - Implementing event loops and handling user interactions.

---

## 9. **Best Practices**

1. **Always Prime Generators:**
   - Call `next()` or `send(None)` before sending data to a coroutine.

2. **Use `asyncio` for Asynchronous Code:**
   - Prefer `async def` and `await` for modern coroutine-based asynchronous programming.

3. **Close Coroutines Properly:**
   - Ensure coroutines are closed when no longer needed to avoid resource leaks.

4. **Handle Exceptions Gracefully:**
   - Use `try`/`except` blocks to catch and handle errors within coroutines.

---

## 10. **Common Pitfalls**

1. **Forgetting to Prime Coroutines:**
   - Calling `send()` before `next()` raises a `TypeError`.

2. **Blocking in Coroutines:**
   - Avoid using blocking operations like `time.sleep()` inside `async def`. Use `await asyncio.sleep()` instead.

3. **Unmanaged Lifecycle:**
   - Not closing coroutines can lead to resource leaks.

---

## 11. **Conclusion**

Coroutines are a powerful feature in Python that enable efficient, asynchronous, and event-driven programming. By combining `async def`, `await`, and generator-based coroutines, you can handle complex workflows, process data streams, and manage I/O operations effectively. Understanding their nuances and proper usage will allow you to write scalable and efficient Python applications.

<a id='states'></a>
# Generator States in Python

Generators in Python are a type of iterable that yield items one at a time using the `yield` keyword. Unlike regular functions, generators have a lifecycle, and their behavior changes depending on their current state. Understanding these states is crucial to effectively use and debug generators.

---

## 1. **What are Generator States?**
A generator in Python can exist in one of the following states:

1. **Created:** The generator object has been created but not yet started.
2. **Running:** The generator is actively executing.
3. **Suspended:** The generator has paused execution at a `yield` statement, waiting to be resumed.
4. **Closed (or Completed):** The generator has finished execution or has been explicitly closed.

These states determine what actions you can perform on the generator and how it behaves when interacting with it.

---

## 2. **How to Determine Generator States?**
Python provides the `inspect` module to check the state of a generator.

### Example:
```python
import inspect

def simple_generator():
    yield 1
    yield 2

# Create generator
gen = simple_generator()

# Check initial state
print(inspect.getgeneratorstate(gen))  # Output: GEN_CREATED

# Advance to the first yield
next(gen)
print(inspect.getgeneratorstate(gen))  # Output: GEN_SUSPENDED

# Exhaust the generator
list(gen)
print(inspect.getgeneratorstate(gen))  # Output: GEN_CLOSED
```

### Generator States:
| **State**         | **Description**                                                   |
|-------------------|-------------------------------------------------------------------|
| `GEN_CREATED`     | The generator is created but not started.                        |
| `GEN_RUNNING`     | The generator is currently executing.                            |
| `GEN_SUSPENDED`   | The generator is paused at a `yield` and waiting to be resumed.  |
| `GEN_CLOSED`      | The generator has terminated, either normally or via an error.   |

---

## 3. **Lifecycle of a Generator**
The lifecycle of a generator can be broken down as follows:

### 3.1 Created:
- A generator is in the `GEN_CREATED` state immediately after it is instantiated.
- It has not yet started execution.

#### Example:
```python
def my_generator():
    yield "Hello"

gen = my_generator()
print(inspect.getgeneratorstate(gen))  # Output: GEN_CREATED
```

### 3.2 Running:
- When the generator is executing its code, it is in the `GEN_RUNNING` state.
- This is a transient state and cannot be directly observed.

#### Example:
```python
def my_generator():
    print("Generator is running")
    yield "Hello"

gen = my_generator()
next(gen)  # Output: Generator is running
```

### 3.3 Suspended:
- When a `yield` is encountered, the generator pauses execution and transitions to `GEN_SUSPENDED`.
- It remains in this state until resumed using `next()` or `send()`.

#### Example:
```python
def my_generator():
    yield "Hello"
    yield "World"

gen = my_generator()
next(gen)  # Suspends at the first yield
print(inspect.getgeneratorstate(gen))  # Output: GEN_SUSPENDED
```

### 3.4 Closed:
- The generator transitions to `GEN_CLOSED` when:
  - The generator function finishes execution.
  - A `GeneratorExit` is raised.
  - The `close()` method is called.

#### Example:
```python
def my_generator():
    yield "Hello"
    yield "World"

gen = my_generator()
list(gen)  # Exhausts the generator
print(inspect.getgeneratorstate(gen))  # Output: GEN_CLOSED
```

---

## 4. **Interacting with Generator States**

### 4.1 Using `next()` to Advance States
- `next()` resumes the generator and advances it to the next `yield` statement.

#### Example:
```python
def counter():
    yield 1
    yield 2

count = counter()
print(inspect.getgeneratorstate(count))  # Output: GEN_CREATED

next(count)
print(inspect.getgeneratorstate(count))  # Output: GEN_SUSPENDED
```

### 4.2 Using `close()` to Terminate Generators
- The `close()` method transitions the generator to the `GEN_CLOSED` state.

#### Example:
```python
def my_generator():
    yield "Hello"
    yield "World"

gen = my_generator()
gen.close()
print(inspect.getgeneratorstate(gen))  # Output: GEN_CLOSED
```

### 4.3 Using `throw()` to Inject Exceptions
- The `throw()` method raises an exception inside the generator.
- If the generator does not handle the exception, it transitions to `GEN_CLOSED`.

#### Example:
```python
def my_generator():
    try:
        yield "Hello"
    except ValueError:
        print("ValueError caught")

    yield "World"

gen = my_generator()
next(gen)
gen.throw(ValueError, "An error occurred")
print(inspect.getgeneratorstate(gen))  # Output: GEN_SUSPENDED
```

---

## 5. **Common Pitfalls and Best Practices**

### 5.1 Forgetting to Prime the Generator
- Generators must be primed (using `next()` or `send(None)`) before sending values.

#### Incorrect:
```python
def my_generator():
    value = yield
    print(value)

gen = my_generator()
gen.send("Hello")  # Raises TypeError: can't send non-None value to a just-started generator
```

#### Correct:
```python
def my_generator():
    value = yield
    print(value)

gen = my_generator()
next(gen)  # Prime the generator
gen.send("Hello")
```

### 5.2 Ignoring Generator Cleanup
- Always ensure that generators are closed when they are no longer needed.

#### Best Practice:
```python
def my_generator():
    try:
        yield "Hello"
    finally:
        print("Cleanup logic executed")

# Usage
gen = my_generator()
next(gen)
gen.close()  # Ensures cleanup logic runs
```

---

## 6. **Conclusion**
Understanding generator states is crucial for writing efficient, bug-free Python code. By leveraging tools like `inspect.getgeneratorstate` and adhering to best practices, you can better manage and debug generator-based workflows. Generators, when used correctly, offer powerful capabilities for lazy evaluation and asynchronous programming.
<a id='sending-data'></a>
# Sending Data to Generators in Python

Generators in Python are not just for producing values; they can also receive data from the caller using the `send()` method. This feature allows for more dynamic and interactive generator behavior, enabling use cases such as coroutines, pipelines, and simulations.

---

## 1. **Basics of Sending Data to Generators**
- The `send()` method sends a value into a generator.
- This value becomes the result of the `yield` expression within the generator.
- The generator must be in the **suspended state** (paused at a `yield` statement) for `send()` to work.

---

## 2. **Priming the Generator**
Before using `send()`, the generator must be **primed**. Priming moves the generator to its first `yield` statement, making it ready to receive data.

### Example:
```python
def echo():
    received = yield  # Pauses here
    print(f"Received: {received}")

# Create and prime the generator
gen = echo()
next(gen)  # Prime the generator

gen.send("Hello")  # Output: Received: Hello
gen.close()  # Cleanly close the generator
```

---

## 3. **How `send()` Works Internally**
- The value passed to `send()` is returned by the `yield` expression inside the generator.
- If the generator is not primed, calling `send()` raises a `TypeError`.

### Example:
```python
def multiplier():
    factor = yield
    while True:
        value = yield
        print(f"Result: {value * factor}")

# Usage
gen = multiplier()
next(gen)  # Prime the generator
gen.send(10)  # Set the factor to 10
gen.send(5)   # Output: Result: 50
gen.send(3)   # Output: Result: 30
gen.close()  # Cleanly close the generator
```

---

## 4. **Combining `send()` with Loops**
Generators can use `send()` within loops to handle continuous streams of input data.

### Example:
```python
def accumulator():
    total = 0
    while True:
        value = yield total  # Send back the current total
        if value is None:
            break
        total += value

# Usage
gen = accumulator()
print(next(gen))  # Prime the generator, Output: 0
print(gen.send(10))  # Add 10, Output: 10
print(gen.send(20))  # Add 20, Output: 30
gen.close()  # Close the generator
```

---

## 5. **Error Handling with `send()`**
Generators can handle exceptions raised by the `send()` method, allowing graceful handling of invalid data.

### Example:
```python
def safe_division():
    try:
        while True:
            numerator, denominator = yield
            if denominator == 0:
                print("Cannot divide by zero")
            else:
                print(f"Result: {numerator / denominator}")
    except GeneratorExit:
        print("Generator closed")

# Usage
gen = safe_division()
next(gen)  # Prime the generator
gen.send((10, 2))  # Output: Result: 5.0
gen.send((10, 0))  # Output: Cannot divide by zero
gen.close()  # Output: Generator closed
```

---

## 6. **Advanced Use Case: Coroutines with `send()`**
Coroutines are a special type of generator designed to consume data interactively, often using `send()`.

### Example: Data Filtering
```python
def data_filter(target):
    while True:
        data = yield
        if data % 2 == 0:
            target.send(data)

def data_printer():
    while True:
        data = yield
        print(f"Filtered data: {data}")

# Setup
printer = data_printer()
next(printer)  # Prime the printer coroutine

filter = data_filter(printer)
next(filter)  # Prime the filter coroutine

filter.send(1)  # No output (1 is odd)
filter.send(2)  # Output: Filtered data: 2
filter.send(3)  # No output (3 is odd)
filter.close()
printer.close()
```

---

## 7. **Comparison: `next()` vs `send()`**

| **Method**       | **Behavior**                                                |
|-------------------|------------------------------------------------------------|
| `next()`          | Advances the generator to the next `yield`, returning its value. |
| `send(value)`     | Sends a value into the generator and resumes execution.      |
| **Commonality**   | Both resume the generator and advance to the next `yield`.   |

---

## 8. **Best Practices**

1. **Prime the Generator:** Always call `next()` or `send(None)` to prime the generator before using `send()`.
2. **Handle Exceptions Gracefully:** Use `try`/`except` to manage invalid data or unexpected states within the generator.
3. **Close Generators Properly:** Use the `close()` method to cleanly terminate generators when they are no longer needed.
4. **Document Input Expectations:** Clearly document the type and format of data expected by the generator.

---

## 9. **Common Pitfalls**

### 9.1 Forgetting to Prime the Generator
```python
def example_gen():
    value = yield
    print(value)

gen = example_gen()
gen.send("data")  # Raises TypeError: can't send non-None value to a just-started generator
```
**Solution:**
```python
next(gen)  # Prime the generator
gen.send("data")
```

### 9.2 Closing Generators Abruptly
If a generator is not closed properly, cleanup code inside `finally` blocks may not execute.

#### Example:
```python
def generator_with_cleanup():
    try:
        while True:
            yield
    finally:
        print("Cleanup executed")

gen = generator_with_cleanup()
next(gen)
gen.close()  # Ensures cleanup runs
```

---

## 10. **Conclusion**
Sending data to generators using `send()` unlocks powerful and dynamic capabilities, allowing them to act as coroutines or interactive data processors. By understanding how to properly prime, send data, and handle exceptions, you can leverage this feature to create efficient, responsive, and robust Python programs.

<a id='exceptions'></a>
# Sending Exceptions to Generators in Python

Generators in Python are not only capable of producing and consuming values but can also handle exceptions sent to them via the `throw()` method. This allows for more sophisticated generator behaviors, such as error handling or cleanup operations, making generators powerful tools for robust data processing and control flow management.

---

## 1. **How to Send Exceptions to Generators**
- Use the `throw(exc_type, exc_value=None, traceback=None)` method to send an exception into a generator.
- The exception is raised at the current suspension point (the last `yield` statement).
- Generators can handle the exception using a `try`/`except` block.
- If the generator does not handle the exception, it propagates to the caller.

---

## 2. **Basic Example: Sending Exceptions**
```python
def generator_with_exception_handling():
    try:
        yield "Start"
    except ValueError as e:
        print(f"Caught ValueError: {e}")
        yield "Recovered"
    yield "End"

# Usage
gen = generator_with_exception_handling()
print(next(gen))  # Output: Start
gen.throw(ValueError, "An error occurred")  # Output: Caught ValueError: An error occurred
print(next(gen))  # Output: End
```
**Explanation:**
- `throw()` raises the exception inside the generator.
- The generator catches the exception and continues execution.

---

## 3. **Exception Handling Workflow**
1. The generator is paused at a `yield` statement.
2. The caller invokes `throw()` with an exception.
3. The exception is raised inside the generator at the suspension point.
4. The generator can:
   - Handle the exception (via `try`/`except`).
   - Propagate the exception to the caller.

---

## 4. **Unhandled Exceptions in Generators**
If a generator does not handle the exception sent via `throw()`, the exception propagates to the caller and the generator terminates.

### Example:
```python
def simple_generator():
    yield "Start"
    yield "Middle"

# Usage
gen = simple_generator()
print(next(gen))  # Output: Start
gen.throw(RuntimeError, "Unhandled error")  # Raises RuntimeError
```

---

## 5. **Finalization with Exceptions**
Generators often use `finally` blocks to perform cleanup when an exception occurs or the generator is closed.

### Example:
```python
def generator_with_cleanup():
    try:
        yield "Working"
    finally:
        print("Cleanup executed")

# Usage
gen = generator_with_cleanup()
print(next(gen))  # Output: Working
gen.throw(RuntimeError, "Something went wrong")  # Output: Cleanup executed
```
**Explanation:**
- The `finally` block executes regardless of how the generator terminates, ensuring cleanup logic runs.

---

## 6. **Using `throw()` for Custom Logic**
### Example: Graceful Error Recovery
```python
def data_processor():
    try:
        while True:
            data = yield
            print(f"Processing: {data}")
    except ValueError as e:
        print(f"Error: {e}. Skipping...")

# Usage
gen = data_processor()
next(gen)  # Prime the generator
gen.send(10)  # Output: Processing: 10
gen.throw(ValueError, "Invalid data")  # Output: Error: Invalid data. Skipping...
gen.send(20)  # Output: Processing: 20
gen.close()
```
**Explanation:**
- The generator gracefully handles a `ValueError` and continues processing subsequent values.

---

## 7. **Chaining Exceptions in Generators**
Multiple generators can be chained, propagating exceptions along the chain.

### Example:
```python
def child_generator():
    try:
        yield "Child Start"
        yield "Child Working"
    except Exception as e:
        print(f"Child caught: {e}")
        raise

def parent_generator():
    try:
        yield from child_generator()
    except Exception as e:
        print(f"Parent caught: {e}")

# Usage
gen = parent_generator()
print(next(gen))  # Output: Child Start
gen.throw(KeyError, "Test KeyError")
# Output:
# Child caught: 'Test KeyError'
# Parent caught: 'Test KeyError'
```

---

## 8. **Common Use Cases**

### 8.1 Error-Tolerant Data Pipelines
Coroutines that skip invalid data but continue processing the rest.

### Example:
```python
def tolerant_pipeline():
    try:
        while True:
            value = yield
            if value < 0:
                raise ValueError("Negative value")
            print(f"Processed: {value}")
    except ValueError as e:
        print(f"Warning: {e}")

# Usage
gen = tolerant_pipeline()
next(gen)
gen.send(10)  # Output: Processed: 10
gen.send(-5)  # Output: Warning: Negative value
gen.send(20)  # Output: Processed: 20
gen.close()
```

### 8.2 Dynamic Error Recovery
Generators that adapt behavior based on the type of exception.

### Example:
```python
def dynamic_error_handler():
    try:
        while True:
            yield
    except ValueError:
        print("Handling ValueError")
    except KeyError:
        print("Handling KeyError")

# Usage
gen = dynamic_error_handler()
next(gen)
gen.throw(ValueError)  # Output: Handling ValueError
next(gen)
gen.throw(KeyError)    # Output: Handling KeyError
```

---

## 9. **Best Practices**
1. **Always Handle Known Exceptions:**
   - Ensure that your generator handles exceptions relevant to its purpose.

2. **Use `finally` for Cleanup:**
   - Always include a `finally` block for resource cleanup.

3. **Propagate or Suppress Carefully:**
   - Decide whether to propagate exceptions to the caller or suppress them within the generator.

4. **Document Expected Exceptions:**
   - Clearly document which exceptions your generator can handle or propagate.

---

## 10. **Common Pitfalls**

### 10.1 Forgetting to Handle Exceptions
If the generator does not handle exceptions, it will terminate abruptly.

### 10.2 Unintended Cleanup Skipping
Failing to include a `finally` block can result in skipped cleanup logic.

### 10.3 Overusing Exception Handling
Catching every exception indiscriminately can hide bugs or unexpected issues.

---

## 11. **Conclusion**
Sending exceptions to generators using `throw()` adds a powerful tool to Python's arsenal for dynamic, interactive workflows. By leveraging this capability, developers can create robust and error-tolerant systems that handle exceptions gracefully and continue functioning as needed. Understanding and applying best practices ensures that this feature is used effectively.

<a id='decorators'></a>
# Using Decorators to Prime Coroutines in Python

Coroutines in Python are a special type of generator that allows values to be sent to them using the `send()` method. However, coroutines require an initial step called **priming**—executing them up to the first `yield` statement—to ensure they are ready to receive values. This process can be automated and simplified using decorators.

---

## 1. **What is Priming a Coroutine?**
- **Priming** involves advancing a coroutine to its first `yield`.
- Without priming, attempting to use `send()` on a coroutine results in a `TypeError`.

### Example of Manual Priming:
```python
def coroutine():
    print("Coroutine started")
    while True:
        value = yield
        print(f"Received: {value}")

# Manual priming
gen = coroutine()
next(gen)  # Prime the coroutine
gen.send("Hello")  # Output: Received: Hello
gen.close()
```
---

## 2. **Automating Priming with Decorators**
A decorator can wrap a coroutine function to automatically prime it when it is called.

### Example:
```python
def coroutine_decorator(func):
    def wrapper(*args, **kwargs):
        gen = func(*args, **kwargs)
        next(gen)  # Automatically prime the coroutine
        return gen
    return wrapper

@coroutine_decorator
def coroutine():
    print("Coroutine started")
    while True:
        value = yield
        print(f"Received: {value}")

# Usage
gen = coroutine()  # Automatically primed

gen.send("Hello")  # Output: Received: Hello
gen.close()
```
**Explanation:**
- The `coroutine_decorator` wraps the coroutine function and primes it automatically by calling `next()`.

---

## 3. **Benefits of Using Decorators**
- **Simplicity:** No need to manually prime the coroutine every time.
- **Error Reduction:** Avoids `TypeError` caused by forgetting to prime the coroutine.
- **Code Reusability:** The same decorator can be reused for multiple coroutine functions.

---

## 4. **Advanced Example: Using Decorators with Arguments**
Decorators can be enhanced to accept arguments, making them more flexible.

### Example:
```python
def coroutine_with_message(message):
    def decorator(func):
        def wrapper(*args, **kwargs):
            gen = func(*args, **kwargs)
            print(message)
            next(gen)
            return gen
        return wrapper
    return decorator

@coroutine_with_message("Priming the coroutine")
def echo():
    while True:
        value = yield
        print(f"Echo: {value}")

# Usage
gen = echo()  # Output: Priming the coroutine
gen.send("Hello")  # Output: Echo: Hello
gen.close()
```
**Explanation:**
- The decorator accepts a `message` argument to print during priming.

---

## 5. **Combining with Coroutine Pipelines**
Decorators can be particularly useful when working with coroutine pipelines, where multiple coroutines pass data to each other.

### Example:
```python
def auto_prime(func):
    def wrapper(*args, **kwargs):
        gen = func(*args, **kwargs)
        next(gen)
        return gen
    return wrapper

@auto_prime
def filter_even(target):
    while True:
        value = yield
        if value % 2 == 0:
            target.send(value)

@auto_prime
def printer():
    while True:
        value = yield
        print(f"Received: {value}")

# Setup pipeline
printer_gen = printer()
filter_gen = filter_even(printer_gen)

# Send data
filter_gen.send(1)  # No output (1 is odd)
filter_gen.send(2)  # Output: Received: 2
filter_gen.close()
printer_gen.close()
```
**Explanation:**
- The `auto_prime` decorator simplifies setting up and using coroutine pipelines by automating priming for each coroutine.

---

## 6. **Best Practices for Using Decorators with Coroutines**

1. **Use a Consistent Naming Convention:**
   - Name your coroutine decorators clearly, such as `@auto_prime` or `@prime_coroutine`.

2. **Document the Behavior:**
   - Indicate in the function docstring that the coroutine is automatically primed by a decorator.

3. **Avoid Side Effects in Decorators:**
   - Ensure the decorator only modifies the priming behavior and does not alter other functionality.

4. **Combine with Exception Handling:**
   - Handle exceptions within the decorator to ensure the coroutine is correctly primed.

---

## 7. **Common Pitfalls**

### 7.1 Forgetting to Decorate the Coroutine
Without the decorator, the coroutine must be manually primed.

### 7.2 Overcomplicating the Decorator
Keep the decorator logic simple and focused on automating priming.

### 7.3 Forgetting to Close the Coroutine
Always close the coroutine to ensure proper cleanup, especially if it contains `finally` blocks.

---

## 8. **Conclusion**
Using decorators to prime coroutines simplifies the process of working with generator-based coroutines. It enhances code readability, reduces errors, and promotes reuse in coroutine-heavy workflows. By automating the priming process, you can focus on building robust and efficient coroutine pipelines without worrying about manual setup.

<a id='two-way'></a>
# `yield from` for Two-Way Communication in Python

The `yield from` statement in Python allows a generator to delegate part of its operations to another generator. Beyond simplifying nested generator code, `yield from` enables two-way communication between the caller and the sub-generator, making it a powerful tool for coroutine pipelines and generator chaining.

---

## 1. **What is `yield from`?**
- **`yield from` Syntax:** Delegates operations from a parent generator to a sub-generator.
- Simplifies looping and data delegation, enabling cleaner and more readable code.
- Facilitates two-way communication: values can be sent to, received from, or exceptions raised within the sub-generator.

### Basic Syntax:
```python
def outer_gen():
    yield from inner_gen()

def inner_gen():
    yield "Hello"
    yield "World"
```

---

## 2. **Two-Way Communication with `yield from`**
Using `yield from`, the caller can:
1. Send values to the sub-generator.
2. Receive values from the sub-generator.
3. Propagate exceptions to the sub-generator.

### Example:
```python
def sub_generator():
    while True:
        value = yield
        print(f"Sub-generator received: {value}")
        yield value * 2

def main_generator():
    result = yield from sub_generator()
    print(f"Main generator result: {result}")

# Usage
gen = main_generator()
next(gen)  # Prime the main generator

gen.send(5)  # Output: Sub-generator received: 5
             # Main generator result: 10
next(gen)    # Prime for the next value
```
**Explanation:**
- `yield from` delegates the handling of `send()` and `yield` to `sub_generator()`.
- `sub_generator` processes the input, produces output, and sends control back to the caller.

---

## 3. **Flow of Data and Control with `yield from`**

1. **Caller to Parent Generator:**
   - The caller interacts with the parent generator via `send()` or `throw()`.
2. **Parent Generator to Sub-Generator:**
   - The parent generator delegates interaction to the sub-generator via `yield from`.
3. **Sub-Generator to Caller:**
   - The sub-generator produces values via `yield`, which are passed to the caller.

### Diagram:
```
Caller ↔ Parent Generator ↔ Sub-Generator
```

---

## 4. **Handling Exceptions with `yield from`**
`yield from` propagates exceptions from the caller to the sub-generator, allowing the sub-generator to handle or propagate them further.

### Example:
```python
def sub_generator():
    try:
        while True:
            value = yield
            print(f"Sub-generator received: {value}")
    except ValueError as e:
        print(f"Sub-generator handled exception: {e}")
        yield "Recovered"

def main_generator():
    yield from sub_generator()

# Usage
gen = main_generator()
next(gen)  # Prime the generator
gen.send(10)  # Output: Sub-generator received: 10
gen.throw(ValueError, "Invalid input")  # Output: Sub-generator handled exception: Invalid input
                                      # Returns: Recovered
```
**Explanation:**
- The exception `ValueError` is raised in `sub_generator` and handled within it.
- After recovery, the generator continues execution.

---

## 5. **Returning Values from Sub-Generators**
Sub-generators can return a final value, which is captured by the parent generator via `yield from`.

### Example:
```python
def sub_generator():
    yield 1
    yield 2
    return "Sub-generator complete"

def main_generator():
    result = yield from sub_generator()
    print(f"Sub-generator returned: {result}")

# Usage
gen = main_generator()
print(list(gen))
# Output:
# 1
# 2
# Sub-generator returned: Sub-generator complete
```
**Explanation:**
- The `return` statement in `sub_generator` passes its value to the `yield from` statement.

---

## 6. **Practical Applications of Two-Way Communication**

### 6.1 Coroutine Pipelines
`yield from` simplifies data pipelines, enabling seamless communication between components.

#### Example:
```python
def pipeline_stage1():
    while True:
        value = yield
        yield value + 1

def pipeline_stage2():
    while True:
        value = yield
        yield value * 2

def pipeline():
    stage1 = pipeline_stage1()
    stage2 = pipeline_stage2()
    next(stage1)
    next(stage2)
    while True:
        value = yield
        result1 = stage1.send(value)
        result2 = stage2.send(result1)
        yield result2

# Usage
gen = pipeline()
next(gen)  # Prime the pipeline
print(gen.send(5))  # Output: 12 (5 → Stage1 → 6 → Stage2 → 12)
```

### 6.2 Parsing Structured Data
```python
def parser():
    while True:
        token = yield
        print(f"Parsing token: {token}")
        if token == "end":
            return "Parsing complete"

def main():
    try:
        result = yield from parser()
        print(result)
    except StopIteration:
        print("Parser finished")

# Usage
gen = main()
next(gen)
gen.send("start")
gen.send("data")
gen.send("end")
# Output:
# Parsing token: start
# Parsing token: data
# Parsing token: end
# Parsing complete
```

---

## 7. **Best Practices**

1. **Understand Data Flow:**
   - Be mindful of how data is sent between the caller, parent generator, and sub-generator.
2. **Handle Exceptions Carefully:**
   - Ensure exceptions are handled at the appropriate level to avoid unexpected crashes.
3. **Use `yield from` for Simplicity:**
   - Replace nested loops with `yield from` to reduce complexity.
4. **Combine with Decorators:**
   - Automate priming of coroutines when using `yield from` for two-way communication.

---

## 8. **Common Pitfalls**

1. **Unprimed Sub-Generators:**
   - Ensure all sub-generators are correctly primed before using `send()` or `throw()`.

2. **Unhandled Exceptions:**
   - Failing to handle exceptions in sub-generators can cause the entire pipeline to fail.

3. **Excessive Nesting:**
   - Avoid deeply nested generators, as it can become challenging to debug. Use `yield from` to flatten the structure.

---

## 9. **Conclusion**
The `yield from` statement simplifies generator delegation and enables seamless two-way communication. By leveraging its capabilities, you can create elegant and efficient coroutine pipelines, process data streams interactively, and handle exceptions gracefully. Understanding and applying `yield from` effectively can greatly enhance the flexibility and readability of your Python code.
<a id='yield-sending-data'></a>
# `yield from` for Sending Data in Python

The `yield from` statement in Python is a powerful tool that delegates control to a sub-generator. It simplifies the process of sending data, handling exceptions, and returning values between the caller, the parent generator, and the sub-generator. This capability makes `yield from` a cornerstone of advanced generator and coroutine workflows.

---

## 1. **What is `yield from`?**
- **Delegation:** `yield from` allows a generator (parent) to delegate operations to another generator (sub-generator).
- **Communication:** Supports seamless two-way communication, where data can flow between the caller and the sub-generator via the parent generator.
- **Simplified Code:** Reduces boilerplate code by managing interactions with the sub-generator automatically.

---

## 2. **Sending Data to Sub-Generators**
Using `yield from`, data sent to the parent generator via `send()` is directly forwarded to the sub-generator. The sub-generator processes the data and can yield results back to the caller.

### Example:
```python
def sub_generator():
    while True:
        value = yield
        print(f"Sub-generator received: {value}")
        yield value * 2

def parent_generator():
    yield from sub_generator()

# Usage
gen = parent_generator()
next(gen)  # Prime the generator
gen.send(5)  # Output: Sub-generator received: 5
             # Yields: 10
```
**Explanation:**
- The caller sends `5` to the parent generator using `send(5)`.
- The parent generator forwards the value to the sub-generator via `yield from`.
- The sub-generator processes the value and returns `10`, which is passed back to the caller.

---

## 3. **How Data Flows Through `yield from`**
### Flow Diagram:
```
Caller ↔ Parent Generator ↔ Sub-Generator
```
1. **Caller → Parent Generator:** Data is sent to the parent generator using `send()`.
2. **Parent Generator → Sub-Generator:** The parent generator forwards the data to the sub-generator via `yield from`.
3. **Sub-Generator → Caller:** The sub-generator processes the data and yields results back to the caller through the parent generator.

---

## 4. **Handling Data in Sub-Generators**
### Example:
```python
def multiplier():
    factor = yield "Send me a factor"
    while True:
        value = yield
        yield value * factor

def parent():
    result = yield from multiplier()
    print(f"Final result: {result}")

# Usage
gen = parent()
print(next(gen))  # Output: Send me a factor
gen.send(3)  # Set the multiplier factor
print(gen.send(5))  # Output: 15 (5 * 3)
print(gen.send(10))  # Output: 30 (10 * 3)
```
**Explanation:**
- The caller interacts with the sub-generator via `yield from`.
- The sub-generator can maintain its own state (e.g., the `factor` variable) while processing inputs from the caller.

---

## 5. **Two-Way Data Pipelines with `yield from`**
`yield from` is particularly useful for creating pipelines where data flows through multiple stages.

### Example:
```python
def add_one():
    while True:
        value = yield
        yield value + 1

def multiply_by_two():
    while True:
        value = yield
        yield value * 2

def pipeline():
    stage1 = add_one()
    stage2 = multiply_by_two()
    next(stage1)
    next(stage2)
    while True:
        value = yield
        result1 = stage1.send(value)
        result2 = stage2.send(result1)
        yield result2

# Usage
gen = pipeline()
next(gen)  # Prime the pipeline
print(gen.send(5))  # Output: 12 (5 → add_one → 6 → multiply_by_two → 12)
```
**Explanation:**
- Data is passed through two sub-generators: `add_one` and `multiply_by_two`.
- The pipeline generator delegates data processing to the sub-generators via `yield from`.

---

## 6. **Returning Values from Sub-Generators**
A sub-generator can use the `return` statement to provide a final value to the parent generator. This value is captured by `yield from`.

### Example:
```python
def sub_generator():
    yield 1
    yield 2
    return "Sub-generator complete"

def parent_generator():
    result = yield from sub_generator()
    print(f"Sub-generator returned: {result}")

# Usage
gen = parent_generator()
print(list(gen))
# Output:
# 1
# 2
# Sub-generator returned: Sub-generator complete
```
**Explanation:**
- The sub-generator returns a value, which is passed to the parent generator and handled after `yield from` completes.

---

## 7. **Handling Exceptions with `yield from`**
Exceptions sent to the parent generator via `throw()` are propagated to the sub-generator. The sub-generator can handle or re-raise these exceptions.

### Example:
```python
def sub_generator():
    try:
        while True:
            value = yield
            print(f"Sub-generator received: {value}")
    except ValueError as e:
        print(f"Sub-generator caught: {e}")
        yield "Recovered"

def parent_generator():
    yield from sub_generator()

# Usage
gen = parent_generator()
next(gen)  # Prime the generator
gen.send(10)  # Output: Sub-generator received: 10
gen.throw(ValueError, "Test error")  # Output: Sub-generator caught: Test error
                                    # Returns: Recovered
```

---

## 8. **Best Practices**

1. **Prime Generators:**
   - Ensure sub-generators are primed before delegating to them with `yield from`.

2. **Graceful Error Handling:**
   - Use `try`/`except` blocks to handle exceptions sent to sub-generators.

3. **Leverage Return Values:**
   - Capture and use return values from sub-generators for additional logic.

4. **Avoid Deep Nesting:**
   - Keep generator delegation shallow to maintain readability.

---

## 9. **Common Pitfalls**

1. **Unprimed Generators:**
   - Forgetting to prime sub-generators results in `TypeError` when `send()` is used.

2. **Unhandled Exceptions:**
   - Ensure all exceptions are appropriately handled or propagated.

3. **Misusing Return Values:**
   - Be aware that `yield from` captures the return value of sub-generators, which must be explicitly handled.

---

## 10. **Conclusion**
The `yield from` statement simplifies sending data to sub-generators, enabling seamless communication between components in generator-based workflows. By mastering its use, you can build efficient, readable pipelines and coroutines that process and transform data interactively. Proper error handling and thoughtful design ensure robust implementations for real-world applications.

<a id='closing'></a>
# `yield from` - Closing and Return in Python

The `yield from` statement in Python not only simplifies delegating operations to sub-generators but also elegantly handles resource cleanup and return values. It provides an effective mechanism for managing generator finalization (closing) and returning values from sub-generators to parent generators.

---

## 1. **What Does `yield from` Do for Closing and Return?**
- **Closing Generators:** When the `close()` method is called on a generator, `yield from` ensures that the sub-generator's cleanup logic (e.g., `finally` blocks) is executed properly.
- **Returning Values:** The `return` statement in a sub-generator provides a value that can be captured by the parent generator via `yield from`.

---

## 2. **Closing Sub-Generators with `yield from`**

When a generator is closed using `close()`, Python raises a `GeneratorExit` exception inside the generator. This exception ensures that all `finally` blocks or cleanup code is executed.

### Example:
```python
def sub_generator():
    try:
        yield 1
        yield 2
    finally:
        print("Sub-generator: Cleanup complete")

def parent_generator():
    yield from sub_generator()
    print("Parent generator: Finished")

# Usage
gen = parent_generator()
print(next(gen))  # Output: 1
print(next(gen))  # Output: 2
gen.close()  # Output: Sub-generator: Cleanup complete
              # Output: Parent generator: Finished
```
**Explanation:**
- The `close()` method on `gen` triggers `GeneratorExit` in the `sub_generator()`.
- The `finally` block ensures cleanup is completed in the sub-generator.

---

## 3. **Returning Values from Sub-Generators**
A sub-generator can return a value using the `return` statement. This value is captured by `yield from` in the parent generator.

### Example:
```python
def sub_generator():
    yield 1
    yield 2
    return "Sub-generator result"

def parent_generator():
    result = yield from sub_generator()
    print(f"Sub-generator returned: {result}")

# Usage
gen = parent_generator()
print(next(gen))  # Output: 1
print(next(gen))  # Output: 2
print(next(gen))  # Output: Sub-generator returned: Sub-generator result
```
**Explanation:**
- The `return` value of the sub-generator (`"Sub-generator result"`) is assigned to the `result` variable in the parent generator.
- The parent generator can process or use this return value as needed.

---

## 4. **Combining Closing and Return**
A sub-generator can have both cleanup logic and a return value. The `yield from` statement ensures that both are handled appropriately.

### Example:
```python
def sub_generator():
    try:
        yield 1
        yield 2
    finally:
        print("Sub-generator cleanup")
    return "Final result"

def parent_generator():
    result = yield from sub_generator()
    print(f"Result from sub-generator: {result}")

# Usage
gen = parent_generator()
print(next(gen))  # Output: 1
print(next(gen))  # Output: 2
gen.close()  # Output: Sub-generator cleanup
```
**Explanation:**
- The `close()` method triggers the `finally` block in the sub-generator to execute cleanup logic.
- The `return` statement can still provide a value if the generator finishes normally.

---

## 5. **Handling Exceptions During Closure**
If an exception is raised during the closure of a sub-generator, it propagates back to the parent generator.

### Example:
```python
def sub_generator():
    try:
        yield 1
    finally:
        print("Sub-generator cleanup")
        raise RuntimeError("Error during cleanup")

def parent_generator():
    try:
        yield from sub_generator()
    except RuntimeError as e:
        print(f"Caught exception: {e}")

# Usage
gen = parent_generator()
print(next(gen))  # Output: 1
gen.close()  # Output: Sub-generator cleanup
              # Output: Caught exception: Error during cleanup
```
**Explanation:**
- Exceptions raised in the sub-generator’s cleanup logic propagate to the parent generator.
- The parent generator can handle these exceptions using a `try`/`except` block.

---

## 6. **Practical Use Case: Managing Resources**
`yield from` simplifies managing resources like files or database connections within a generator.

### Example:
```python
def file_reader(file_name):
    try:
        with open(file_name, "r") as f:
            for line in f:
                yield line.strip()
    finally:
        print("File reader: File closed")

def parent_generator(file_name):
    result = yield from file_reader(file_name)
    print(f"Final result: {result}")

# Usage
file_name = "example.txt"
with open(file_name, "w") as f:
    f.write("Line 1\nLine 2\n")

gen = parent_generator(file_name)
print(next(gen))  # Output: Line 1
print(next(gen))  # Output: Line 2
gen.close()  # Output: File reader: File closed
```
**Explanation:**
- The `file_reader` generator reads lines from a file and ensures the file is closed when finished.
- The parent generator uses `yield from` to delegate file reading and cleanup to the sub-generator.

---

## 7. **Best Practices**
1. **Always Handle Cleanup:**
   - Use `finally` blocks in sub-generators to ensure proper resource cleanup.

2. **Capture Return Values:**
   - Use the value returned by the sub-generator to perform additional processing in the parent generator.

3. **Gracefully Handle Exceptions:**
   - Use `try`/`except` blocks to handle exceptions during generator closure or cleanup.

4. **Combine with Context Managers:**
   - Pair `yield from` with context managers for more robust resource management.

---

## 8. **Common Pitfalls**

1. **Forgetting to Handle Return Values:**
   - If the parent generator doesn’t capture the return value, it may miss important information from the sub-generator.

2. **Unhandled Exceptions in Cleanup:**
   - Exceptions in a sub-generator’s `finally` block can propagate unexpectedly. Always handle them in the parent generator.

3. **Overusing Deep Nesting:**
   - Avoid deeply nested `yield from` chains, as they can make the code harder to debug and maintain.

---

## 9. **Conclusion**
The `yield from` statement simplifies delegating generator operations, managing resource cleanup, and capturing return values. By handling closure and return effectively, `yield from` enables robust and readable generator workflows. With proper exception handling and resource management, it becomes a powerful tool for building advanced, maintainable Python applications.

<a id='throwing-exceptions'></a>
# `yield from` - Throwing Exceptions in Python

The `yield from` statement in Python facilitates generator delegation and also provides a seamless way to propagate exceptions from the caller to a sub-generator. This capability is especially useful in managing errors in complex generator workflows and coroutine pipelines.

---

## 1. **What Does `yield from` Do for Exceptions?**

When the `throw()` method is called on a generator:
- The exception is raised at the point where the generator is paused (i.e., the current `yield` statement).
- If the generator is using `yield from`, the exception is propagated to the sub-generator.
- The sub-generator can handle the exception, ignore it, or propagate it further.

---

## 2. **Basic Example: Throwing Exceptions**

### Example:
```python
def sub_generator():
    try:
        while True:
            value = yield
            print(f"Sub-generator received: {value}")
    except ValueError as e:
        print(f"Sub-generator caught: {e}")
        yield "Recovered"

def parent_generator():
    yield from sub_generator()

# Usage
gen = parent_generator()
next(gen)  # Prime the generator
gen.send(10)  # Output: Sub-generator received: 10
gen.throw(ValueError, "Test exception")  # Output: Sub-generator caught: Test exception
                                        # Yields: Recovered
```
**Explanation:**
- The exception `ValueError` is sent to the sub-generator via `throw()`.
- The sub-generator catches the exception in its `try`/`except` block and yields a recovery value.

---

## 3. **Exception Propagation with `yield from`**

### How Exceptions Propagate:
1. **Caller → Parent Generator:** The caller uses `throw()` on the parent generator.
2. **Parent Generator → Sub-Generator:** The parent generator forwards the exception to the sub-generator via `yield from`.
3. **Sub-Generator → Parent Generator:** The sub-generator handles or propagates the exception back to the parent generator.

---

## 4. **Example: Handling Exceptions in Parent and Sub-Generators**

### Example:
```python
def sub_generator():
    try:
        while True:
            value = yield
            print(f"Sub-generator received: {value}")
    except KeyError as e:
        print(f"Sub-generator handled KeyError: {e}")
        yield "Recovered"

def parent_generator():
    try:
        yield from sub_generator()
    except ValueError as e:
        print(f"Parent generator handled ValueError: {e}")

# Usage
gen = parent_generator()
next(gen)  # Prime the generator
gen.send(42)  # Output: Sub-generator received: 42
gen.throw(KeyError, "Sub-generator error")  # Output: Sub-generator handled KeyError: 'Sub-generator error'
                                           # Yields: Recovered
gen.throw(ValueError, "Parent generator error")  # Output: Parent generator handled ValueError: Parent generator error
```
**Explanation:**
- The sub-generator handles `KeyError` exceptions.
- The parent generator handles `ValueError` exceptions.
- Each generator manages the exceptions relevant to its logic.

---

## 5. **Returning Values After Handling Exceptions**

A sub-generator can handle an exception and still return a value via the `return` statement. The return value is captured by the parent generator.

### Example:
```python
def sub_generator():
    try:
        yield 1
        yield 2
    except RuntimeError as e:
        print(f"Sub-generator caught RuntimeError: {e}")
        return "Sub-generator completed with error"

def parent_generator():
    result = yield from sub_generator()
    print(f"Sub-generator returned: {result}")

# Usage
gen = parent_generator()
print(next(gen))  # Output: 1
print(next(gen))  # Output: 2
gen.throw(RuntimeError, "Test error")  # Output: Sub-generator caught RuntimeError: Test error
                                       # Output: Sub-generator returned: Sub-generator completed with error
```
**Explanation:**
- The sub-generator returns a value after handling an exception, which is captured by the parent generator.

---

## 6. **Common Use Cases for Exception Handling with `yield from`**

### 6.1 Graceful Shutdown
When exceptions are used to signal termination or cleanup.

#### Example:
```python
def sub_generator():
    try:
        yield 1
        yield 2
    finally:
        print("Sub-generator cleanup")

def parent_generator():
    try:
        yield from sub_generator()
    except GeneratorExit:
        print("Parent generator cleanup")

# Usage
gen = parent_generator()
print(next(gen))  # Output: 1
print(next(gen))  # Output: 2
gen.close()  # Output: Sub-generator cleanup
             # Output: Parent generator cleanup
```

### 6.2 Error-Tolerant Pipelines
Allowing parts of a pipeline to recover from errors without stopping the entire process.

#### Example:
```python
def error_tolerant_stage():
    try:
        while True:
            value = yield
            print(f"Processing: {value}")
    except ValueError as e:
        print(f"Handled ValueError: {e}")
        yield "Recovered"

def pipeline():
    yield from error_tolerant_stage()

# Usage
gen = pipeline()
next(gen)  # Prime the pipeline
gen.send(10)  # Output: Processing: 10
gen.throw(ValueError, "Pipeline error")  # Output: Handled ValueError: Pipeline error
                                        # Yields: Recovered
```

---

## 7. **Best Practices**

1. **Handle Relevant Exceptions:**
   - Ensure that each generator handles exceptions relevant to its specific responsibilities.

2. **Use `finally` for Cleanup:**
   - Use `finally` blocks to ensure that cleanup code runs during exception handling or generator closure.

3. **Propagate or Suppress Thoughtfully:**
   - Decide whether exceptions should be handled locally, propagated, or logged.

4. **Document Expected Exceptions:**
   - Clearly document the types of exceptions that each generator can handle or propagate.

---

## 8. **Common Pitfalls**

1. **Uncaught Exceptions:**
   - Ensure all exceptions are either handled or properly propagated to avoid unexpected termination.

2. **Ignoring GeneratorExit:**
   - Failing to handle `GeneratorExit` in `finally` blocks can lead to resource leaks.

3. **Overcomplicating Exception Handling:**
   - Avoid overly complex exception logic that makes the generator difficult to understand or debug.

---

## 9. **Conclusion**

The `yield from` statement provides a clean and powerful mechanism for propagating exceptions between generators. By leveraging this feature, you can build robust, error-tolerant workflows that gracefully handle errors and perform necessary cleanup. With proper design and thoughtful exception management, `yield from` can significantly simplify complex generator-based pipelines.

<a id='pulling-data'></a>
# Pipelines - Pulling Data in Python

A pipeline in Python is a sequence of connected data processing stages where the output of one stage serves as the input to the next. In a **pull-based pipeline**, the downstream stages pull data from upstream stages. This mechanism allows for on-demand data processing, which is memory efficient and suitable for large datasets or real-time processing.

---

## 1. **What is a Pull-Based Pipeline?**
- A pull-based pipeline is controlled by the consumer, which requests data from the pipeline as needed.
- Each stage in the pipeline processes data lazily and only when it is requested.
- This approach reduces memory usage by processing data incrementally.

### Key Characteristics:
1. **Lazy Evaluation:** Data is processed only when needed.
2. **Chained Generators:** Each stage is implemented as a generator.
3. **On-Demand Processing:** Ideal for large datasets or streaming data.

---

## 2. **Building Blocks of a Pull-Based Pipeline**
### Components:
1. **Data Source:** Provides raw input data.
2. **Transformers:** Apply processing to the data.
3. **Sink (Consumer):** Requests and consumes the processed data.

### Example Pipeline Structure:
```
Data Source → Transformer 1 → Transformer 2 → Consumer
```

---

## 3. **Implementing a Pull-Based Pipeline**

### Example:
```python
def data_source():
    """Simulates a data source."""
    for i in range(1, 6):
        print(f"Producing: {i}")
        yield i

def transformer_stage(generator, multiplier):
    """Applies a transformation to the data."""
    for value in generator:
        transformed = value * multiplier
        print(f"Transforming {value} to {transformed}")
        yield transformed

def consumer(generator):
    """Consumes and processes the transformed data."""
    for value in generator:
        print(f"Consuming: {value}")

# Create the pipeline
source = data_source()
stage1 = transformer_stage(source, 2)  # Multiply by 2
stage2 = transformer_stage(stage1, 3)  # Multiply by 3

# Start consuming data
consumer(stage2)
```
**Output:**
```
Producing: 1
Transforming 1 to 2
Transforming 2 to 6
Consuming: 6
Producing: 2
Transforming 2 to 4
Transforming 4 to 12
Consuming: 12
...
```
**Explanation:**
- The pipeline consists of a source, two transformation stages, and a consumer.
- Data flows lazily through the pipeline, and each stage processes data only when the consumer requests it.

---

## 4. **Advantages of Pull-Based Pipelines**
1. **Memory Efficiency:**
   - Only one piece of data is processed at a time, reducing memory overhead.

2. **Modularity:**
   - Each stage is independent and can be reused or modified.

3. **Scalability:**
   - Suitable for large datasets that cannot fit into memory.

4. **Debuggability:**
   - Each stage can be debugged separately.

---

## 5. **Extending the Pipeline**

### Adding Filtering:
```python
def filter_stage(generator, predicate):
    """Filters data based on a predicate."""
    for value in generator:
        if predicate(value):
            print(f"Filtering: {value} passes")
            yield value
        else:
            print(f"Filtering: {value} dropped")

# Extended pipeline with filtering
source = data_source()
stage1 = transformer_stage(source, 2)
stage2 = filter_stage(stage1, lambda x: x % 4 == 0)  # Keep only multiples of 4
stage3 = transformer_stage(stage2, 3)

consumer(stage3)
```
**Output:**
```
Producing: 1
Transforming 1 to 2
Filtering: 2 dropped
Producing: 2
Transforming 2 to 4
Filtering: 4 passes
Transforming 4 to 12
Consuming: 12
...
```

### Adding Aggregation:
```python
def aggregation_stage(generator):
    """Aggregates data by summing it up."""
    total = 0
    for value in generator:
        total += value
        print(f"Aggregating: Running total = {total}")
        yield total

# Pipeline with aggregation
source = data_source()
stage1 = transformer_stage(source, 2)
stage2 = aggregation_stage(stage1)
consumer(stage2)
```

---

## 6. **Best Practices for Pull-Based Pipelines**

1. **Keep Stages Simple:**
   - Each stage should have a single responsibility to improve modularity and maintainability.

2. **Leverage Lazy Evaluation:**
   - Ensure that data is processed incrementally to avoid memory bottlenecks.

3. **Handle Errors Gracefully:**
   - Add exception handling in each stage to manage unexpected data or failures.

4. **Test Each Stage Independently:**
   - Isolate and test individual stages to simplify debugging.

---

## 7. **Common Pitfalls**

1. **Forgetting to Prime Generators:**
   - Generators need to be primed (e.g., using `next()`) before sending or pulling data.

2. **Excessive Nesting:**
   - Avoid deeply nested pipelines to maintain code readability.

3. **Unoptimized Stages:**
   - Ensure each stage processes data efficiently to avoid bottlenecks.

4. **Not Closing Generators:**
   - Explicitly close generators when they are no longer needed to release resources.

---

## 8. **Conclusion**

Pull-based pipelines are a powerful design pattern for processing data incrementally. By chaining simple generator-based stages, you can create scalable and memory-efficient workflows. Thoughtful design and adherence to best practices ensure that pull-based pipelines are both robust and maintainable.

<a id='broadcasting'></a>
# Pipelines - Broadcasting in Python

Broadcasting in a pipeline refers to sending the same data to multiple downstream stages or consumers simultaneously. This technique is useful when the same data needs to be processed in different ways or sent to multiple systems for parallel tasks like logging, monitoring, and analytics.

---

## 1. **What is Broadcasting in Pipelines?**
- Broadcasting is a mechanism for distributing the same piece of data to multiple pipeline stages or consumers.
- It is often implemented using **fan-out** logic where a single producer feeds multiple consumers.
- Broadcasting ensures that each consumer receives a copy of the data without interfering with other consumers.

### Use Cases:
1. Logging and monitoring simultaneously.
2. Processing data with different transformations in parallel.
3. Splitting a dataset into multiple storage systems (e.g., databases, files).

---

## 2. **Basic Structure of a Broadcasting Pipeline**
### Conceptual Diagram:
```
Data Source → Broadcasting Stage → [Consumer 1, Consumer 2, Consumer 3]
```

### Example:
```python
def data_source():
    """Produces data to be broadcasted."""
    for i in range(1, 6):
        print(f"Producing: {i}")
        yield i

def broadcast(generator, *consumers):
    """Broadcasts data to multiple consumers."""
    for value in generator:
        print(f"Broadcasting: {value}")
        for consumer in consumers:
            consumer.send(value)

def consumer(name):
    """Receives broadcasted data."""
    while True:
        value = yield
        print(f"{name} received: {value}")

# Create consumers
consumer1 = consumer("Consumer 1")
consumer2 = consumer("Consumer 2")
next(consumer1)  # Prime the consumers
next(consumer2)

# Broadcast data
source = data_source()
broadcast(source, consumer1, consumer2)
```
**Output:**
```
Producing: 1
Broadcasting: 1
Consumer 1 received: 1
Consumer 2 received: 1
Producing: 2
Broadcasting: 2
Consumer 1 received: 2
Consumer 2 received: 2
...
```
**Explanation:**
- The `broadcast` function sends each piece of data from the source to both `consumer1` and `consumer2`.
- Each consumer processes the data independently.

---

## 3. **Advanced Broadcasting with Transformations**
Broadcasting can include transformations applied to the data before it reaches the consumers.

### Example:
```python
def transformer(name, multiplier):
    """Applies a transformation to the broadcasted data."""
    while True:
        value = yield
        transformed = value * multiplier
        print(f"{name} transformed: {value} to {transformed}")

def broadcast_with_transforms(generator, *stages):
    """Broadcasts data through multiple transformation stages."""
    for value in generator:
        for stage in stages:
            stage.send(value)

# Create transformation stages
stage1 = transformer("Stage 1", 2)
stage2 = transformer("Stage 2", 3)
next(stage1)  # Prime the transformers
next(stage2)

# Broadcast data
source = data_source()
broadcast_with_transforms(source, stage1, stage2)
```
**Output:**
```
Producing: 1
Stage 1 transformed: 1 to 2
Stage 2 transformed: 1 to 3
Producing: 2
Stage 1 transformed: 2 to 4
Stage 2 transformed: 2 to 6
...
```
**Explanation:**
- Each stage processes the broadcasted data independently with its transformation logic.

---

## 4. **Broadcasting to Dynamic Consumers**
In real-world scenarios, the number of consumers may vary. Broadcasting pipelines can dynamically add or remove consumers.

### Example:
```python
def dynamic_broadcast(generator, consumers):
    """Broadcasts data to a dynamic list of consumers."""
    for value in generator:
        print(f"Broadcasting: {value}")
        for consumer in consumers:
            consumer.send(value)

def add_consumer(consumers, name):
    """Adds a new consumer to the pipeline."""
    new_consumer = consumer(name)
    next(new_consumer)  # Prime the consumer
    consumers.append(new_consumer)

# Create a list of consumers
consumers = []
add_consumer(consumers, "Consumer 1")
add_consumer(consumers, "Consumer 2")

# Broadcast data dynamically
source = data_source()
dynamic_broadcast(source, consumers)
```
**Output:**
```
Producing: 1
Broadcasting: 1
Consumer 1 received: 1
Consumer 2 received: 1
Producing: 2
Broadcasting: 2
Consumer 1 received: 2
Consumer 2 received: 2
...
```
**Explanation:**
- Consumers can be added dynamically, making the pipeline flexible and scalable.

---

## 5. **Applications of Broadcasting Pipelines**

1. **Logging and Monitoring:**
   - Send data to a logging system and a monitoring dashboard simultaneously.

2. **Data Replication:**
   - Distribute data to multiple storage systems, e.g., a database and a file system.

3. **Parallel Processing:**
   - Apply different processing logic to the same data in parallel (e.g., analytics and reporting).

4. **Real-Time Event Systems:**
   - Broadcast events to multiple subscribers in a publish-subscribe model.

---

## 6. **Best Practices for Broadcasting Pipelines**

1. **Prime Consumers:**
   - Always prime consumers before broadcasting data to ensure they are ready to process input.

2. **Error Handling:**
   - Add error handling in consumers to prevent failures in one consumer from affecting others.

3. **Avoid Bottlenecks:**
   - Ensure that no single consumer slows down the entire pipeline.

4. **Dynamic Management:**
   - Use dynamic broadcasting for pipelines where the number of consumers may change over time.

---

## 7. **Common Pitfalls**

1. **Unprimed Generators:**
   - Forgetting to prime consumers can result in `TypeError` when sending data.

2. **Inefficient Processing:**
   - Avoid overly complex logic in consumers that can delay the entire pipeline.

3. **Unmanaged Resource Cleanup:**
   - Ensure consumers and generators are properly closed when the pipeline is no longer active.

---

## 8. **Conclusion**

Broadcasting in pipelines allows you to efficiently distribute data to multiple consumers or processing stages. By leveraging Python generators, you can create scalable and memory-efficient broadcast systems. Thoughtful design and error handling ensure that these pipelines are robust and maintainable, making them suitable for real-world applications like logging, monitoring, and data replication.
